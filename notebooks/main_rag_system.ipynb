{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1VC0LXFF2tB"
      },
      "source": [
        "# RAG Question Answering System\n",
        "## DS8008 Final Project - Manav Patel (500967756)\n",
        "\n",
        "This notebook demonstrates a complete Retrieval-Augmented Generation (RAG) system for question answering using:\n",
        "- Document chunking and preprocessing\n",
        "- FAISS vector indexing for semantic search\n",
        "- SentenceTransformer embeddings\n",
        "- RoBERTa-based question answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC29-SS4F2Mw",
        "outputId": "1e8aa8c7-26b2-4fe8-d522-ecd843051e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Working directory: /content/drive/MyDrive/Colab Notebooks/DS8008/FinalProject\n",
            "Files: ['.ipynb_checkpoints', 'Final Project', 'FinalProjectDocuments.txt', 'numbered_questions.txt']\n"
          ]
        }
      ],
      "source": [
        "# Setup and data loading\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Set working directory to project root\n",
        "project_root = os.path.abspath('..')  # Assuming notebook is in notebooks/ folder\n",
        "os.chdir(project_root)\n",
        "\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "print(\"Data files:\", os.listdir('data/'))\n",
        "print(\"Project structure:\")\n",
        "for root, dirs, files in os.walk('.'):\n",
        "    level = root.replace('.', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:3]:  # Show first 3 files only\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 3:\n",
        "        print(f\"{subindent}... and {len(files)-3} more files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AO_4YhvAbhu"
      },
      "source": [
        "## 1. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkTivjR-F6kx",
        "outputId": "8c45e4b1-9b04-4658-86f6-3676f79768d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Example text from the document:  beginners bbq class taking place in missoula! do you want to get better at making delicious bbq? you will have the opportunity, put this on your calendar now. thursday, september 22nd join world class bbq champion, tony balay from lonestar smoke rangers. he will be teaching a beginner level class for everyone who wants to get better with their culinary skills. he will teach you everything you need to know to compete in a kcbs bbq competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. the cost to be in the class is $35 per person, and for spectators it is free. included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared. discussion in 'mac os x lion (10.7)' started by axboi87, jan 20, 2012. i've got a 500gb internal drive and a 240gb ssd. when trying to restore using disk utility i'm given the error \"not enough space on disk ____ to restore\" but i shouldn't have to do that!!! any ideas or workarounds before resorting to the above? use carbon copy cloner to copy one drive to the other. i've done this several times going from larger hdd to smaller ssd and i wound up with a bootable ssd drive. one step you have to remember not to skip is to use disk utility to partition the ssd as guid partition scheme hfs+ before doing the clone. if it came apple partition scheme, even if you let ccc do the clone, the resulting drive won't be bootable. ccc usually works in \"file mode\" and it can easily copy a larger drive (that's mostly empty) onto a smaller drive. if you tell ccc to clone a drive you did not boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if i recall). i've actually done this somehow on disk utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. definitely format the drive cloning to first, as bootable apple etc.. thanks for pointing this out. my only experience using du to go larger to smaller was when i was trying to make a lion install stick and i was unable to restore installesd.dmg to a 4 gb usb stick but of course the reason that wouldn't fit is there was slightly more than 4 gb of data. foil plaid lycra and spandex shortall with metallic slinky insets. attached metallic elastic belt with o-ring. headband inc\n",
            "\n",
            "\n",
            "First 10 characters: beginners \n",
            "Last 10 characters: d so much?\n",
            "Length of document: 64520873 characters\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import os\n",
        "import re\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from collections import Counter\n",
        "\n",
        "# Download NLTK punkt tokenizer\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load document corpus\n",
        "with open(\"data/document_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    documents_text = f.read()\n",
        "\n",
        "# Preprocess text\n",
        "documents_text = documents_text.lower()\n",
        "documents_text = re.sub(r'\\s+', ' ', documents_text)\n",
        "\n",
        "# Display document statistics\n",
        "print('Example text from document:')\n",
        "print(documents_text[:2500])\n",
        "document_length = len(documents_text)\n",
        "print(f\"\\nDocument statistics:\")\n",
        "print(f\"- Total characters: {document_length:,}\")\n",
        "print(f\"- First 10 chars: '{documents_text[:10]}'\")\n",
        "print(f\"- Last 10 chars: '{documents_text[-10:]}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Naomip81aW",
        "outputId": "6ecd530b-63b7-4d56-ed7c-885e5407ec6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20 questions.\n",
            "                                             question\n",
            "0   How many scrolls were in the grand library of ...\n",
            "1            Where can the bluefire crystal be found?\n",
            "2   In what year did Dr. Helena Carter win the Nob...\n",
            "3             What is the national bird of Veridonia?\n",
            "4   What was the name of the first space station o...\n",
            "5                    What is Lake Virelia famous for?\n",
            "6      When was 'Echoes of Tomorrow' first published?\n",
            "7   How long did it take the Zephyr-9 to fly aroun...\n",
            "8   Who developed the first AI capable of composin...\n",
            "9                   How many moons does Xyphora have?\n",
            "10  What is the seating capacity of the Grand Arca...\n",
            "11         Where is the silver-tailed lynx native to?\n",
            "12                 When was the ChronoGem discovered?\n",
            "13                         How tall is Solaris Tower?\n",
            "14                       What was Novaterra built on?\n",
            "15                       When was Vortexium invented?\n",
            "16          How long does the Luminara Festival last?\n",
            "17                    How many people speak Nythrani?\n",
            "18         Which cities does the HyperLoop-5 connect?\n",
            "19                 Where is the Moonshade Rose found?\n"
          ]
        }
      ],
      "source": [
        "# Load evaluation questions\n",
        "with open(\"data/evaluation_questions.txt\", \"r\") as f:\n",
        "    questions_list = f.readlines()\n",
        "\n",
        "# Clean questions (remove numbering if present)\n",
        "questions_list = [re.sub(r'^\\d+\\.\\s*', '', q.strip()) for q in questions_list]\n",
        "questions_df = pd.DataFrame(questions_list, columns=[\"question\"])\n",
        "\n",
        "print(f\"Loaded {len(questions_list)} evaluation questions\")\n",
        "print(\"\\nFirst 5 questions:\")\n",
        "for i, q in enumerate(questions_list[:5]):\n",
        "    print(f\"{i+1}. {q}\")\n",
        "    \n",
        "print(f\"\\nQuestions DataFrame shape: {questions_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfcKEwu1Am1r"
      },
      "source": [
        "##### Chunking (sing nltk tokenize), embedding (using all-MiniLM-L6-v2), FAISS Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSLatuO4HO7d",
        "outputId": "33a8d954-ad12-45dd-baa5-5eb6279faa8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading SentenceTransformer model: all-MiniLM-L6-v2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            " SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "print(\"Loading SentenceTransformer model: all-MiniLM-L6-v2...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model loaded.\\n\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOvo_SDKQPTD",
        "outputId": "a9e7cde7-7cdc-4fd4-ff15-8e0a55fd369d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting chunking process...\n",
            "\n",
            "Sentence-based chunking complete. Total chunks created: 599342\n",
            "\n",
            "Chunking done\n",
            "Chunk 1 Preview:\n",
            "beginners bbq class taking place in missoula! do you want to get better at making delicious bbq?\n",
            "\n",
            "Chunk 2 Preview:\n",
            "do you want to get better at making delicious bbq? you will have the opportunity, put this on your calendar now.\n",
            "\n",
            "Chunk 3 Preview:\n",
            "you will have the opportunity, put this on your calendar now. thursday, september 22nd join world class bbq champion, tony balay from lonestar smoke rangers.\n",
            "\n",
            "Chunk 4 Preview:\n",
            "thursday, september 22nd join world class bbq champion, tony balay from lonestar smoke rangers. he will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
            "\n",
            "Chunk 5 Preview:\n",
            "he will be teaching a beginner level class for everyone who wants to get better with their culinary skills. he will teach you everything you need to know to compete in a kcbs bbq competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# chunking documents\n",
        "def chunk_lines_with_context(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    if len(sentences) < 2:\n",
        "        print(\"Not enough sentences to form chunks with overlap. Returning original text as one chunk.\")\n",
        "        return [text]\n",
        "    chunks = []\n",
        "    for i in range(len(sentences) - 1):\n",
        "        chunk = \" \".join([sentences[i], sentences[i+1]])\n",
        "        chunks.append(chunk)\n",
        "    print(f\"\\nSentence-based chunking complete. Total chunks created: {len(chunks)}\\n\")\n",
        "    return chunks\n",
        "print(\"Starting chunking process...\")\n",
        "documents_chunks = chunk_lines_with_context(documents_text)\n",
        "print('Chunking done');\n",
        "for i in range(min(5, len(documents_chunks))):\n",
        "    print(f\"Chunk {i + 1} Preview:\\n{documents_chunks[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d1G0_NmQUWm",
        "outputId": "6982cdf9-49d4-481b-eff9-8b54aab08854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding 599342 chunks in batches of 512...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding chunks: 100%|██████████| 1171/1171 [03:01<00:00,  6.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding complete.\n",
            "\n",
            "Embeddings: \n",
            " [[ 0.03934662 -0.00078637 -0.08404719 ...  0.01195637 -0.10189318\n",
            "  -0.02531926]\n",
            " [-0.01363128 -0.00736005 -0.03140329 ... -0.02576192 -0.09384691\n",
            "  -0.05192094]\n",
            " [-0.00906869 -0.00554028 -0.07197446 ... -0.06166822 -0.1257587\n",
            "  -0.0520644 ]\n",
            " ...\n",
            " [-0.02728089  0.1552      0.02050948 ...  0.09405284 -0.08236547\n",
            "  -0.04060027]\n",
            " [-0.0573018   0.18655883  0.03014164 ...  0.06408855 -0.00851724\n",
            "  -0.02787329]\n",
            " [ 0.06139382  0.13654158 -0.01217416 ...  0.01146802  0.06740606\n",
            "   0.01805817]]\n"
          ]
        }
      ],
      "source": [
        "# Compute Embeddings in Batches of 512\n",
        "def embed_documents_in_batches(docs, batch_size=512):\n",
        "    print(f\"Embedding {len(docs)} chunks in batches of {batch_size}...\")\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(docs), batch_size), desc=\"Embedding chunks\"):\n",
        "        batch = docs[i:i + batch_size]\n",
        "        batch_embeddings = model.encode(batch, convert_to_numpy=True)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    print(\"Embedding complete.\\n\")\n",
        "    return np.vstack(embeddings)\n",
        "embeddings = embed_documents_in_batches(documents_chunks)\n",
        "print(\"Embeddings: \\n\", embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxZpEXv5QWAU",
        "outputId": "a586e519-1e71-4f5d-af33-d5a37c54ec76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building FAISS index with 599342 vectors...\n",
            "FAISS index built.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# building FAISS Index\n",
        "def build_faiss_index(embeddings):\n",
        "    print(f\"Building FAISS index with {len(embeddings)} vectors...\")\n",
        "    d = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    index.add(embeddings)\n",
        "    print(\"FAISS index built.\\n\")\n",
        "    return index\n",
        "faiss_index = build_faiss_index(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dCbFXC9NjXm",
        "outputId": "ed183554-eabf-4a95-f5aa-22fcae9e07b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index: \n",
            " <faiss.swigfaiss_avx512.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7944251f9d70> >\n",
            "Document ChunksL \n",
            " 599342\n",
            "\n",
            "Embeddings: \n",
            " [[ 0.03934662 -0.00078637 -0.08404719 ...  0.01195637 -0.10189318\n",
            "  -0.02531926]\n",
            " [-0.01363128 -0.00736005 -0.03140329 ... -0.02576192 -0.09384691\n",
            "  -0.05192094]\n",
            " [-0.00906869 -0.00554028 -0.07197446 ... -0.06166822 -0.1257587\n",
            "  -0.0520644 ]\n",
            " ...\n",
            " [-0.02728089  0.1552      0.02050948 ...  0.09405284 -0.08236547\n",
            "  -0.04060027]\n",
            " [-0.0573018   0.18655883  0.03014164 ...  0.06408855 -0.00851724\n",
            "  -0.02787329]\n",
            " [ 0.06139382  0.13654158 -0.01217416 ...  0.01146802  0.06740606\n",
            "   0.01805817]]\n"
          ]
        }
      ],
      "source": [
        "# FAISS Retrieval for Input Question\n",
        "print('FAISS index: \\n', faiss_index)\n",
        "print(f\"Document ChunksL \\n {len(documents_chunks)}\")\n",
        "print('\\nEmbeddings: \\n', embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75zaZZY505N8",
        "outputId": "b02fa724-e6dc-462f-d8ab-d62f3d5a3e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample question: \n",
            " How many scrolls were in the grand library of Zandoria?\n",
            "Encoding question: \"How many scrolls were in the grand library of Zandoria?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n"
          ]
        }
      ],
      "source": [
        "# retrieves top k chunks\n",
        "def retrieve_top_k_chunks(question, k=3):\n",
        "    print(f\"Encoding question: \\\"{question}\\\"\")\n",
        "    question_embedding = model.encode([question], convert_to_numpy=True)\n",
        "    print(f\"Querying FAISS index for top {k} relevant chunks...\")\n",
        "    distances, indices = faiss_index.search(question_embedding, k)\n",
        "    top_chunks = [(documents_chunks[i], distances[0][rank]) for rank, i in enumerate(indices[0])]\n",
        "    return top_chunks\n",
        "\n",
        "sample_question = questions_df.iloc[0]['question']\n",
        "print('sample question: \\n', sample_question)\n",
        "top_chunks = retrieve_top_k_chunks(sample_question, k=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4G0j0zrEIQg"
      },
      "source": [
        "##### Answering all questions based on roberta-base-squad2 QA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22R4aF59hb4Y",
        "outputId": "38e4b71d-e14a-4ca3-8aa8-acf1961bc01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA model: 'deepset/roberta-base-squad2'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QA model loaded.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# QA over top-k chunks and choose best answer\n",
        "\n",
        "# Load QA model\n",
        "print(\"Loading QA model: 'deepset/roberta-base-squad2'...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", tokenizer=\"deepset/roberta-base-squad2\")\n",
        "print(\"QA model loaded.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmfYbHOTXITz",
        "outputId": "f738e9ee-8b10-464e-99b0-ac0f76212221"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many scrolls were in the grand library of Zandoria?\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def normalize_distances(distances):\n",
        "    min_val = min(distances)\n",
        "    max_val = max(distances)\n",
        "    if max_val == min_val:\n",
        "        return [0 for _ in distances]\n",
        "    return [(d - min_val) / (max_val - min_val) for d in distances]\n",
        "\n",
        "def get_best_answer_from_chunks_aggregated(question, top_chunks, weight=0.5):\n",
        "    distances = [distance for (_, distance) in top_chunks]\n",
        "    norm_distances = normalize_distances(distances)\n",
        "    answers = []\n",
        "    print(f\"Evaluating QA over top {len(top_chunks)} chunks\\n\")\n",
        "    for i, (chunk, _) in enumerate(top_chunks):\n",
        "        result = qa_pipeline(question=question, context=chunk)\n",
        "        result[\"chunk_index\"] = i\n",
        "        result[\"retrieval_distance\"] = norm_distances[i]\n",
        "        result[\"context\"] = chunk\n",
        "        result[\"combined_score\"] = result[\"score\"] - weight * result[\"retrieval_distance\"]\n",
        "        answers.append(result)\n",
        "    answers_sorted = sorted(answers, key=lambda x: x['combined_score'], reverse=True)\n",
        "    best_answer = answers_sorted[0]\n",
        "    return best_answer\n",
        "\n",
        "print(sample_question)\n",
        "best_answer_result = get_best_answer_from_chunks_aggregated(sample_question, top_chunks, weight=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0lqD6SDPUyw7"
      },
      "outputs": [],
      "source": [
        "# here we use this function to compute a token-f1 score, without a ground truth\n",
        "def compute_token_f1(predicted_answer, context):\n",
        "\n",
        "    if not predicted_answer.strip():\n",
        "        return 0.0, \"N/A\"\n",
        "\n",
        "    def tokenize(text):\n",
        "        return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "    pred_tokens = set(tokenize(predicted_answer))\n",
        "    if not pred_tokens:\n",
        "        return 0.0, \"N/A\"\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    best_sentence = \"\"\n",
        "\n",
        "    for sentence in sent_tokenize(context):\n",
        "        sent_tokens = set(tokenize(sentence))\n",
        "        if not sent_tokens:\n",
        "            continue\n",
        "\n",
        "        common = pred_tokens & sent_tokens\n",
        "        if not common:\n",
        "            continue\n",
        "\n",
        "        precision = len(common) / len(pred_tokens)\n",
        "        recall = len(common) / len(sent_tokens)\n",
        "        if precision + recall == 0:\n",
        "            continue\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_sentence = sentence\n",
        "\n",
        "    return best_f1, best_sentence if best_sentence else \"N/A\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "co6gmkIGUSTF",
        "outputId": "2f627cf5-0188-4960-b3b1-294e153e7f5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How many scrolls were in the grand library of Zandoria?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:   5%|▌         | 1/20 [00:00<00:11,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"Where can the bluefire crystal be found?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  10%|█         | 2/20 [00:01<00:10,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"In what year did Dr. Helena Carter win the Nobel Prize?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  15%|█▌        | 3/20 [00:01<00:09,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"What is the national bird of Veridonia?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  20%|██        | 4/20 [00:02<00:09,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"What was the name of the first space station of the Andromeda Federation?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  25%|██▌       | 5/20 [00:02<00:08,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"What is Lake Virelia famous for?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  30%|███       | 6/20 [00:03<00:08,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"When was 'Echoes of Tomorrow' first published?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  35%|███▌      | 7/20 [00:04<00:07,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How long did it take the Zephyr-9 to fly around the world?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  40%|████      | 8/20 [00:04<00:07,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"Who developed the first AI capable of composing symphonies?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  45%|████▌     | 9/20 [00:05<00:06,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How many moons does Xyphora have?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  50%|█████     | 10/20 [00:05<00:05,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"What is the seating capacity of the Grand Arcadium?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  55%|█████▌    | 11/20 [00:06<00:05,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"Where is the silver-tailed lynx native to?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  60%|██████    | 12/20 [00:07<00:04,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"When was the ChronoGem discovered?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  65%|██████▌   | 13/20 [00:07<00:04,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How tall is Solaris Tower?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  70%|███████   | 14/20 [00:08<00:03,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"What was Novaterra built on?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  75%|███████▌  | 15/20 [00:08<00:02,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"When was Vortexium invented?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  80%|████████  | 16/20 [00:09<00:02,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How long does the Luminara Festival last?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  85%|████████▌ | 17/20 [00:10<00:01,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"How many people speak Nythrani?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  90%|█████████ | 18/20 [00:10<00:01,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"Which cities does the HyperLoop-5 connect?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating all questions:  95%|█████████▌| 19/20 [00:11<00:00,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding question: \"Where is the Moonshade Rose found?\"\n",
            "Querying FAISS index for top 50 relevant chunks...\n",
            "Evaluating QA over top 50 chunks\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating all questions: 100%|██████████| 20/20 [00:11<00:00,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---Final Results Table:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Question ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"How many scrolls were in the grand library of Zandoria?\",\n          \"How many people speak Nythrani?\",\n          \"When was Vortexium invented?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"50,000\",\n          \"over 10 million\",\n          \"2095\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best-Matched Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"the ancient city of zandoria was founded in 1200 bc and was known for its grand library, which housed over 50,000 scrolls.\",\n          \"the fictional language of nythrani is spoken by over 10 million people in the continent of sylvaria.\",\n          \"the synthetic metal alloy vortexium was invented in 2095 and is twice as strong as titanium.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Token-Level F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07377432783406718,\n        \"min\": 0.1053,\n        \"max\": 0.3333,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.3333,\n          0.1081,\n          0.1667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6a58483b-06d8-4e79-ade1-b5a062c953c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Predicted Answer</th>\n",
              "      <th>Best-Matched Sentence</th>\n",
              "      <th>Token-Level F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How many scrolls were in the grand library of Zandoria?</td>\n",
              "      <td>50,000</td>\n",
              "      <td>the ancient city of zandoria was founded in 1200 bc and was known for its grand library, which housed over 50,000 scrolls.</td>\n",
              "      <td>0.1667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Where can the bluefire crystal be found?</td>\n",
              "      <td>caves of mount eldoria</td>\n",
              "      <td>this 17th day of january , 1989. the rare bluefire crystal can only be found in the caves of mount eldoria and emits a faint glow in the dark.</td>\n",
              "      <td>0.2857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>In what year did Dr. Helena Carter win the Nobel Prize?</td>\n",
              "      <td>1998</td>\n",
              "      <td>dr. helena carter won the 1998 nobel prize in chemistry for discovering the synthesis of eco-friendly polymers.</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What is the national bird of Veridonia?</td>\n",
              "      <td>emerald falcon</td>\n",
              "      <td>the national bird of the fictional country of veridonia is the emerald falcon, known for its vibrant green feathers.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>What was the name of the first space station of the Andromeda Federation?</td>\n",
              "      <td>nexus-1</td>\n",
              "      <td>the first space station of the andromeda federation, called nexus-1, was launched in 2142. first, install the dependencies.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>What is Lake Virelia famous for?</td>\n",
              "      <td>purple-hued waters</td>\n",
              "      <td>lake virelia is famous for its purple-hued waters, which change color slightly during sunrise and sunset.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>When was 'Echoes of Tomorrow' first published?</td>\n",
              "      <td>2035</td>\n",
              "      <td>the novel 'echoes of tomorrow' by julian spence was first published in 2035 and became an instant bestseller.</td>\n",
              "      <td>0.1053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>How long did it take the Zephyr-9 to fly around the world?</td>\n",
              "      <td>42 hours</td>\n",
              "      <td>the zephyr-9 aircraft set a record by flying non-stop around the world in just 42 hours.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Who developed the first AI capable of composing symphonies?</td>\n",
              "      <td>elliot grayson</td>\n",
              "      <td>professor elliot grayson developed the first ai capable of composing symphonies in 2078. the decision of whether or not to carry on to do second degree is an incredibly personal one.</td>\n",
              "      <td>0.1333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>How many moons does Xyphora have?</td>\n",
              "      <td>three</td>\n",
              "      <td>the fictional planet of xyphora has three moons: trelos, mornis, and zephyria.</td>\n",
              "      <td>0.1538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>What is the seating capacity of the Grand Arcadium?</td>\n",
              "      <td>150,000</td>\n",
              "      <td>the grand arcadium in lysoria is the largest indoor arena in the world, with a seating capacity of 150,000. standing out in the noisy world of social media is very important because these are the platform where most people spend their time on.</td>\n",
              "      <td>0.1081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Where is the silver-tailed lynx native to?</td>\n",
              "      <td>frostwood region</td>\n",
              "      <td>the silver-tailed lynx, native to the frostwood region, is known for its ability to camouflage in snowy environments.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>When was the ChronoGem discovered?</td>\n",
              "      <td>1876</td>\n",
              "      <td>the chronogem, an ancient relic believed to alter time perception, was discovered in 1876 in the ruins of elysara.</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>How tall is Solaris Tower?</td>\n",
              "      <td>1,250 meters</td>\n",
              "      <td>solaris tower, the tallest building in neo-tokyo, stands at an impressive height of 1,250 meters.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>What was Novaterra built on?</td>\n",
              "      <td>floating platforms</td>\n",
              "      <td>the city of novaterra was built entirely on floating platforms, designed to withstand massive ocean waves.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>When was Vortexium invented?</td>\n",
              "      <td>2095</td>\n",
              "      <td>the synthetic metal alloy vortexium was invented in 2095 and is twice as strong as titanium.</td>\n",
              "      <td>0.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>How long does the Luminara Festival last?</td>\n",
              "      <td>seven days</td>\n",
              "      <td>the annual luminara festival in ardentia lasts for seven days and features grand fireworks displays each night.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>How many people speak Nythrani?</td>\n",
              "      <td>over 10 million</td>\n",
              "      <td>the fictional language of nythrani is spoken by over 10 million people in the continent of sylvaria.</td>\n",
              "      <td>0.3333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>Which cities does the HyperLoop-5 connect?</td>\n",
              "      <td>orionis and eldoria</td>\n",
              "      <td>the hyperloop-5 train connects the cities of orionis and eldoria, reducing travel time to just 25 minutes.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Where is the Moonshade Rose found?</td>\n",
              "      <td>nightfall valley</td>\n",
              "      <td>the moonshade rose, a rare flower that blooms only under a full moon, is found exclusively in the nightfall valley.</td>\n",
              "      <td>0.2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a58483b-06d8-4e79-ade1-b5a062c953c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a58483b-06d8-4e79-ade1-b5a062c953c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a58483b-06d8-4e79-ade1-b5a062c953c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-968b3583-08e4-47d4-a0c1-18866c50905d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-968b3583-08e4-47d4-a0c1-18866c50905d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-968b3583-08e4-47d4-a0c1-18866c50905d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cb4afa0f-e0b7-4c6b-8f6a-6f2ab690725b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cb4afa0f-e0b7-4c6b-8f6a-6f2ab690725b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Question ID  \\\n",
              "0             0   \n",
              "1             1   \n",
              "2             2   \n",
              "3             3   \n",
              "4             4   \n",
              "5             5   \n",
              "6             6   \n",
              "7             7   \n",
              "8             8   \n",
              "9             9   \n",
              "10           10   \n",
              "11           11   \n",
              "12           12   \n",
              "13           13   \n",
              "14           14   \n",
              "15           15   \n",
              "16           16   \n",
              "17           17   \n",
              "18           18   \n",
              "19           19   \n",
              "\n",
              "                                                                     Question  \\\n",
              "0                     How many scrolls were in the grand library of Zandoria?   \n",
              "1                                    Where can the bluefire crystal be found?   \n",
              "2                     In what year did Dr. Helena Carter win the Nobel Prize?   \n",
              "3                                     What is the national bird of Veridonia?   \n",
              "4   What was the name of the first space station of the Andromeda Federation?   \n",
              "5                                            What is Lake Virelia famous for?   \n",
              "6                              When was 'Echoes of Tomorrow' first published?   \n",
              "7                  How long did it take the Zephyr-9 to fly around the world?   \n",
              "8                 Who developed the first AI capable of composing symphonies?   \n",
              "9                                           How many moons does Xyphora have?   \n",
              "10                        What is the seating capacity of the Grand Arcadium?   \n",
              "11                                 Where is the silver-tailed lynx native to?   \n",
              "12                                         When was the ChronoGem discovered?   \n",
              "13                                                 How tall is Solaris Tower?   \n",
              "14                                               What was Novaterra built on?   \n",
              "15                                               When was Vortexium invented?   \n",
              "16                                  How long does the Luminara Festival last?   \n",
              "17                                            How many people speak Nythrani?   \n",
              "18                                 Which cities does the HyperLoop-5 connect?   \n",
              "19                                         Where is the Moonshade Rose found?   \n",
              "\n",
              "          Predicted Answer  \\\n",
              "0                   50,000   \n",
              "1   caves of mount eldoria   \n",
              "2                     1998   \n",
              "3           emerald falcon   \n",
              "4                  nexus-1   \n",
              "5       purple-hued waters   \n",
              "6                     2035   \n",
              "7                 42 hours   \n",
              "8           elliot grayson   \n",
              "9                    three   \n",
              "10                 150,000   \n",
              "11        frostwood region   \n",
              "12                    1876   \n",
              "13            1,250 meters   \n",
              "14      floating platforms   \n",
              "15                    2095   \n",
              "16              seven days   \n",
              "17         over 10 million   \n",
              "18     orionis and eldoria   \n",
              "19        nightfall valley   \n",
              "\n",
              "                                                                                                                                                                                                                                  Best-Matched Sentence  \\\n",
              "0                                                                                                                            the ancient city of zandoria was founded in 1200 bc and was known for its grand library, which housed over 50,000 scrolls.   \n",
              "1                                                                                                        this 17th day of january , 1989. the rare bluefire crystal can only be found in the caves of mount eldoria and emits a faint glow in the dark.   \n",
              "2                                                                                                                                       dr. helena carter won the 1998 nobel prize in chemistry for discovering the synthesis of eco-friendly polymers.   \n",
              "3                                                                                                                                  the national bird of the fictional country of veridonia is the emerald falcon, known for its vibrant green feathers.   \n",
              "4                                                                                                                           the first space station of the andromeda federation, called nexus-1, was launched in 2142. first, install the dependencies.   \n",
              "5                                                                                                                                             lake virelia is famous for its purple-hued waters, which change color slightly during sunrise and sunset.   \n",
              "6                                                                                                                                         the novel 'echoes of tomorrow' by julian spence was first published in 2035 and became an instant bestseller.   \n",
              "7                                                                                                                                                              the zephyr-9 aircraft set a record by flying non-stop around the world in just 42 hours.   \n",
              "8                                                                professor elliot grayson developed the first ai capable of composing symphonies in 2078. the decision of whether or not to carry on to do second degree is an incredibly personal one.   \n",
              "9                                                                                                                                                                        the fictional planet of xyphora has three moons: trelos, mornis, and zephyria.   \n",
              "10  the grand arcadium in lysoria is the largest indoor arena in the world, with a seating capacity of 150,000. standing out in the noisy world of social media is very important because these are the platform where most people spend their time on.   \n",
              "11                                                                                                                                the silver-tailed lynx, native to the frostwood region, is known for its ability to camouflage in snowy environments.   \n",
              "12                                                                                                                                   the chronogem, an ancient relic believed to alter time perception, was discovered in 1876 in the ruins of elysara.   \n",
              "13                                                                                                                                                    solaris tower, the tallest building in neo-tokyo, stands at an impressive height of 1,250 meters.   \n",
              "14                                                                                                                                           the city of novaterra was built entirely on floating platforms, designed to withstand massive ocean waves.   \n",
              "15                                                                                                                                                         the synthetic metal alloy vortexium was invented in 2095 and is twice as strong as titanium.   \n",
              "16                                                                                                                                      the annual luminara festival in ardentia lasts for seven days and features grand fireworks displays each night.   \n",
              "17                                                                                                                                                 the fictional language of nythrani is spoken by over 10 million people in the continent of sylvaria.   \n",
              "18                                                                                                                                           the hyperloop-5 train connects the cities of orionis and eldoria, reducing travel time to just 25 minutes.   \n",
              "19                                                                                                                                  the moonshade rose, a rare flower that blooms only under a full moon, is found exclusively in the nightfall valley.   \n",
              "\n",
              "    Token-Level F1  \n",
              "0           0.1667  \n",
              "1           0.2857  \n",
              "2           0.1111  \n",
              "3           0.2222  \n",
              "4           0.2222  \n",
              "5           0.3000  \n",
              "6           0.1053  \n",
              "7           0.2105  \n",
              "8           0.1333  \n",
              "9           0.1538  \n",
              "10          0.1081  \n",
              "11          0.2105  \n",
              "12          0.1111  \n",
              "13          0.3000  \n",
              "14          0.2222  \n",
              "15          0.1250  \n",
              "16          0.2105  \n",
              "17          0.3333  \n",
              "18          0.3000  \n",
              "19          0.2000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# answering all the question and computing the token-f1 score, with no ground truth\n",
        "\n",
        "# Store results\n",
        "all_results = []\n",
        "\n",
        "# Loop over all questions\n",
        "for idx, row in tqdm(questions_df.iterrows(), total=len(questions_df), desc=\"Evaluating all questions\"):\n",
        "    question_id = row['id'] if 'id' in row else idx\n",
        "    question = row['question']\n",
        "    top_chunks = retrieve_top_k_chunks(question, k=50)\n",
        "    best_answer_result = get_best_answer_from_chunks_aggregated(question, top_chunks, weight = 0.9)\n",
        "    context_text = top_chunks[best_answer_result['chunk_index']][0]\n",
        "    f1_score, matched_sentence = compute_token_f1(best_answer_result['answer'], context_text)\n",
        "    all_results.append({\n",
        "        \"Question ID\": question_id,\n",
        "        \"Question\": question,\n",
        "        \"Predicted Answer\": best_answer_result['answer'],\n",
        "        # \"Confidence Score\": best_answer_result['score'],\n",
        "        # \"Retrieval Similarity\": best_answer_result['retrieval_distance'],\n",
        "        # \"Combined Score\": best_answer_result['combined_score'],\n",
        "        \"Best-Matched Sentence\": matched_sentence,\n",
        "        \"Token-Level F1\": round(f1_score, 4)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "from IPython.display import display\n",
        "print(\"\\n---Final Results Table:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dl5o7uOO_Oml"
      },
      "outputs": [],
      "source": [
        "# now computing token-f1 score, with a defined ground truth\n",
        "\n",
        "# ground truth for token-f1\n",
        "ground_truth_data = {\n",
        "    \"Question Number\": list(range(20)),\n",
        "    \"Question\": [\n",
        "        \"How many scrolls were in the grand library of Zandoria?\",\n",
        "        \"Where can the bluefire crystal be found?\",\n",
        "        \"In what year did Dr. Helena Carter win the Nobel Prize?\",\n",
        "        \"What is the national bird of Veridonia?\",\n",
        "        \"What was the name of the first space station of the Andromeda Federation?\",\n",
        "        \"What is Lake Virelia famous for?\",\n",
        "        \"When was 'Echoes of Tomorrow' first published?\",\n",
        "        \"How long did it take the Zephyr-9 to fly around the world?\",\n",
        "        \"Who developed the first AI capable of composing symphonies?\",\n",
        "        \"How many moons does Xyphora have?\",\n",
        "        \"What is the seating capacity of the Grand Arcadium?\",\n",
        "        \"Where is the silver-tailed lynx native to?\",\n",
        "        \"When was the ChronoGem discovered?\",\n",
        "        \"How tall is Solaris Tower?\",\n",
        "        \"What was Novaterra built on?\",\n",
        "        \"When was Vortexium invented?\",\n",
        "        \"How long does the Luminara Festival last?\",\n",
        "        \"How many people speak Nythrani?\",\n",
        "        \"Which cities does the HyperLoop-5 connect?\",\n",
        "        \"Where is the Moonshade Rose found?\"\n",
        "    ],\n",
        "    \"Answer\": [\n",
        "        \"50,000\",\n",
        "        \"caves of mount eldoria\",\n",
        "        \"1998\",\n",
        "        \"emerald falcon\",\n",
        "        \"nexus-1\",\n",
        "        \"purple-hued waters\",\n",
        "        \"2035\",\n",
        "        \"42 hours\",\n",
        "        \"elliot grayson\",\n",
        "        \"three\",\n",
        "        \"150,000\",\n",
        "        \"frostwood region\",\n",
        "        \"1876\",\n",
        "        \"1,250 meters\",\n",
        "        \"floating platforms\",\n",
        "        \"2095\",\n",
        "        \"seven days\",\n",
        "        \"over 10 million\",\n",
        "        \"orionis and eldoria\",\n",
        "        \"nightfall valley\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "ground_truth_df = pd.DataFrame(ground_truth_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g32f0K1kUSt9",
        "outputId": "9dcd1d52-170c-4f89-d892-ff9176abe30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 100.00%\n",
            "Average Token-Level F1 Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    tokens = re.findall(r'\\w+', text)\n",
        "    return tokens\n",
        "\n",
        "def compute_token_f1_groundtruth(predicted, ground_truth):\n",
        "    predicted_tokens = tokenize(predicted)\n",
        "    ground_truth_tokens = tokenize(ground_truth)\n",
        "    common_tokens = Counter(predicted_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common_tokens.values())\n",
        "    if num_same == 0:\n",
        "        return 0.0\n",
        "\n",
        "    precision = num_same / len(predicted_tokens)\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def compute_metrics(results_df, ground_truth_df):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    total_f1 = 0.0\n",
        "\n",
        "    for index, row in results_df.iterrows():\n",
        "        question = row[\"Question\"]\n",
        "        predicted_answer = row[\"Predicted Answer\"]\n",
        "        try:\n",
        "            ground_truth_answer = ground_truth_df.loc[ground_truth_df['Question'] == question, 'Answer'].iloc[0]\n",
        "        except IndexError:\n",
        "            continue\n",
        "        if predicted_answer.strip().lower() == ground_truth_answer.strip().lower():\n",
        "            correct_predictions += 1\n",
        "        f1 = compute_token_f1_groundtruth(predicted_answer, ground_truth_answer)\n",
        "        total_f1 += f1\n",
        "        total_predictions += 1\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0\n",
        "    avg_f1 = total_f1 / total_predictions if total_predictions > 0 else 0.0\n",
        "    return accuracy, avg_f1\n",
        "\n",
        "\n",
        "# Compute metrics based on the ground truth and the results\n",
        "accuracy, avg_f1 = compute_metrics(results_df, ground_truth_df)\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Average Token-Level F1 Score: {avg_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkUHpU2_F5hP"
      },
      "source": [
        "##### Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dZFSRZoAtSG_",
        "outputId": "94fd8033-696f-4f5b-dc0a-445826a375c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---1) Results and token-f1 (no ground truth):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Question ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Predicted Answer</th>\n",
              "      <th>Best-Matched Sentence</th>\n",
              "      <th>Token-Level F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>How many scrolls were in the grand library of Zandoria?</td>\n",
              "      <td>50,000</td>\n",
              "      <td>the ancient city of zandoria was founded in 1200 bc and was known for its grand library, which housed over 50,000 scrolls.</td>\n",
              "      <td>0.1667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Where can the bluefire crystal be found?</td>\n",
              "      <td>caves of mount eldoria</td>\n",
              "      <td>this 17th day of january , 1989. the rare bluefire crystal can only be found in the caves of mount eldoria and emits a faint glow in the dark.</td>\n",
              "      <td>0.2857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>In what year did Dr. Helena Carter win the Nobel Prize?</td>\n",
              "      <td>1998</td>\n",
              "      <td>dr. helena carter won the 1998 nobel prize in chemistry for discovering the synthesis of eco-friendly polymers.</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>What is the national bird of Veridonia?</td>\n",
              "      <td>emerald falcon</td>\n",
              "      <td>the national bird of the fictional country of veridonia is the emerald falcon, known for its vibrant green feathers.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>What was the name of the first space station of the Andromeda Federation?</td>\n",
              "      <td>nexus-1</td>\n",
              "      <td>the first space station of the andromeda federation, called nexus-1, was launched in 2142. first, install the dependencies.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>What is Lake Virelia famous for?</td>\n",
              "      <td>purple-hued waters</td>\n",
              "      <td>lake virelia is famous for its purple-hued waters, which change color slightly during sunrise and sunset.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>When was 'Echoes of Tomorrow' first published?</td>\n",
              "      <td>2035</td>\n",
              "      <td>the novel 'echoes of tomorrow' by julian spence was first published in 2035 and became an instant bestseller.</td>\n",
              "      <td>0.1053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>How long did it take the Zephyr-9 to fly around the world?</td>\n",
              "      <td>42 hours</td>\n",
              "      <td>the zephyr-9 aircraft set a record by flying non-stop around the world in just 42 hours.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>Who developed the first AI capable of composing symphonies?</td>\n",
              "      <td>elliot grayson</td>\n",
              "      <td>professor elliot grayson developed the first ai capable of composing symphonies in 2078. the decision of whether or not to carry on to do second degree is an incredibly personal one.</td>\n",
              "      <td>0.1333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>How many moons does Xyphora have?</td>\n",
              "      <td>three</td>\n",
              "      <td>the fictional planet of xyphora has three moons: trelos, mornis, and zephyria.</td>\n",
              "      <td>0.1538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>What is the seating capacity of the Grand Arcadium?</td>\n",
              "      <td>150,000</td>\n",
              "      <td>the grand arcadium in lysoria is the largest indoor arena in the world, with a seating capacity of 150,000. standing out in the noisy world of social media is very important because these are the platform where most people spend their time on.</td>\n",
              "      <td>0.1081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>Where is the silver-tailed lynx native to?</td>\n",
              "      <td>frostwood region</td>\n",
              "      <td>the silver-tailed lynx, native to the frostwood region, is known for its ability to camouflage in snowy environments.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>When was the ChronoGem discovered?</td>\n",
              "      <td>1876</td>\n",
              "      <td>the chronogem, an ancient relic believed to alter time perception, was discovered in 1876 in the ruins of elysara.</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>How tall is Solaris Tower?</td>\n",
              "      <td>1,250 meters</td>\n",
              "      <td>solaris tower, the tallest building in neo-tokyo, stands at an impressive height of 1,250 meters.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>What was Novaterra built on?</td>\n",
              "      <td>floating platforms</td>\n",
              "      <td>the city of novaterra was built entirely on floating platforms, designed to withstand massive ocean waves.</td>\n",
              "      <td>0.2222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>When was Vortexium invented?</td>\n",
              "      <td>2095</td>\n",
              "      <td>the synthetic metal alloy vortexium was invented in 2095 and is twice as strong as titanium.</td>\n",
              "      <td>0.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>How long does the Luminara Festival last?</td>\n",
              "      <td>seven days</td>\n",
              "      <td>the annual luminara festival in ardentia lasts for seven days and features grand fireworks displays each night.</td>\n",
              "      <td>0.2105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>How many people speak Nythrani?</td>\n",
              "      <td>over 10 million</td>\n",
              "      <td>the fictional language of nythrani is spoken by over 10 million people in the continent of sylvaria.</td>\n",
              "      <td>0.3333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>Which cities does the HyperLoop-5 connect?</td>\n",
              "      <td>orionis and eldoria</td>\n",
              "      <td>the hyperloop-5 train connects the cities of orionis and eldoria, reducing travel time to just 25 minutes.</td>\n",
              "      <td>0.3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>Where is the Moonshade Rose found?</td>\n",
              "      <td>nightfall valley</td>\n",
              "      <td>the moonshade rose, a rare flower that blooms only under a full moon, is found exclusively in the nightfall valley.</td>\n",
              "      <td>0.2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------\n",
            "---2) Results and token-f1 (with ground truth):\n",
            "\n",
            "Token-F1 score, with ground truth: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "print(\"---1) Results and token-f1 (no ground truth):\")\n",
        "display(HTML(results_df.to_html(index=False)))\n",
        "print('----------------------------------------------------------------------------------------')\n",
        "print(\"---2) Results and token-f1 (with ground truth):\")\n",
        "# display(HTML(results_df[['Question ID', 'Question', 'Predicted Answer', 'Best-Matched Sentence']].to_html(index=False)))\n",
        "print(f\"\\nToken-F1 score, with ground truth: {avg_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jWGkC-d3G_Dz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
